# Euterpe Training Code

***

[![Open In Colab][colab-badge]][colab-notebook1]

[colab-notebook1]: <https://colab.research.google.com/github/asigalov61/Euterpe/blob/main/Training-Code/Euterpe_Maker.ipynb>
[colab-badge]: <https://colab.research.google.com/assets/colab-badge.svg>

***

### NOTE ON OTHER TRANSFORMERS/TRAINING CODE VERSIONS:

### 1) Perceiver-AR seems to work best with very good results and convergence on huge seq_len (64k)
### 2) FLASH also shows very good results and convergence but with shorter seq_len
### 3) Mega performs below average
### 4) Linear and Sinkhorn perform average, but they are old and not SOTA/efficient anymore

***

### Project Los Angeles
### Tegridy Code 2022
