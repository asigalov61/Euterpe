{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "ac5a4cf0-d9d2-47b5-9633-b53f8d99a4d2",
          "kernelId": ""
        },
        "id": "SiTIpPjArIyr"
      },
      "source": [
        "# Euterpe Maker (ver. 1.0)\n",
        "\n",
        "***\n",
        "\n",
        "Powered by tegridy-tools: https://github.com/asigalov61/tegridy-tools\n",
        "\n",
        "***\n",
        "\n",
        "Credit for GPT2-RGA code used in this colab goes out @ Sashmark97 https://github.com/Sashmark97/midigen and @ Damon Gwinn https://github.com/gwinndr/MusicTransformer-Pytorch\n",
        "\n",
        "***\n",
        "\n",
        "WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect. https://www.nscai.gov/\n",
        "\n",
        "***\n",
        "\n",
        "#### Project Los Angeles\n",
        "\n",
        "#### Tegridy Code 2022\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "fa0a611c-1803-42ae-bdf6-a49b5a4e781b",
          "kernelId": ""
        },
        "id": "gOd93yV0sGd2"
      },
      "source": [
        "# (Setup Environment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "39411b40-9e39-416e-8fe4-d40f733e7956",
          "kernelId": ""
        },
        "id": "lw-4aqV3sKQG"
      },
      "outputs": [],
      "source": [
        "#@title nvidia-smi gpu check\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "a1a45a91-d909-4fd4-b67a-5e16b971d179",
          "kernelId": ""
        },
        "id": "fX12Yquyuihc",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install all dependencies (run only once per session)\n",
        "\n",
        "!git clone https://github.com/asigalov61/Euterpe\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "b8207b76-9514-4c07-95db-95a4742e52c5",
          "kernelId": ""
        },
        "id": "z7n9vnKmug1J"
      },
      "outputs": [],
      "source": [
        "#@title Import all needed modules\n",
        "\n",
        "print('Loading needed modules. Please wait...')\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import secrets\n",
        "\n",
        "if not os.path.exists('/content/Dataset'):\n",
        "    os.makedirs('/content/Dataset')\n",
        "\n",
        "if not os.path.exists('/content/INTS'):\n",
        "    os.makedirs('/content/INTS')\n",
        "\n",
        "print('Loading TMIDIX and GPT2RGAX modules...')\n",
        "os.chdir('/content/Euterpe')\n",
        "import TMIDIX\n",
        "from GPT2RGAX import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.chdir('/content/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "20b8698a-0b4e-4fdb-ae49-24d063782e77",
          "kernelId": ""
        },
        "id": "ObPxlEutsQBj"
      },
      "source": [
        "# (FROM SCRATCH) Download and process MIDI dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acquire MMD Dataset here and untar it to the ./Dataset dir\n",
        "\n",
        "https://github.com/jeffreyjohnens/MetaMIDIDataset"
      ],
      "metadata": {
        "id": "IID1-w0wldhy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "ffbb7a2a-d91a-477f-ac89-56d77d6cdf42",
          "kernelId": ""
        },
        "id": "snIZ3xKPsPgB"
      },
      "outputs": [],
      "source": [
        "#@title Download original LAKH MIDI Dataset here\n",
        "\n",
        "%cd /content/Dataset/\n",
        "\n",
        "!wget 'http://hog.ee.columbia.edu/craffel/lmd/lmd_full.tar.gz'\n",
        "!tar -xvf 'lmd_full.tar.gz'\n",
        "!rm 'lmd_full.tar.gz'\n",
        "\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (PROCESS)"
      ],
      "metadata": {
        "id": "JwrqQeie08t0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processing is going to be done in chunks due to huge size of the datasets"
      ],
      "metadata": {
        "id": "PjSzq-QTmuD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scan the ./Dataset dir/MIDI files and save the file list just in case\n",
        "###########\n",
        "\n",
        "print('Loading MIDI files...')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "\n",
        "dataset_addr = \"/content/Dataset\"\n",
        "# os.chdir(dataset_addr)\n",
        "filez = list()\n",
        "for (dirpath, dirnames, filenames) in os.walk(dataset_addr):\n",
        "    filez += [os.path.join(dirpath, file) for file in filenames]\n",
        "print('=' * 70)\n",
        "\n",
        "if filez == []:\n",
        "    print('Could not find any MIDI files. Please check Dataset dir...')\n",
        "    print('=' * 70)\n",
        "\n",
        "print('Randomizing file list...')\n",
        "random.shuffle(filez)\n",
        "\n",
        "TMIDIX.Tegridy_Any_Pickle_File_Writer(filez, '/content/Euterpe-MIDIs-File-List')"
      ],
      "metadata": {
        "id": "DuVWtdDNcqKh",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LOAD/RELOAD MIDI file list\n",
        "filez = TMIDIX.Tegridy_Any_Pickle_File_Reader('/content/Euterpe-MIDIs-File-List')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DIPW5c2Jml85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Process MIDIs with TMIDIX MIDI processor\n",
        "\n",
        "sorted_or_random_file_loading_order = False # Sorted order is NOT usually recommended\n",
        "dataset_ratio = 1 # Change this if you need more data\n",
        "\n",
        "\n",
        "print('TMIDIX MIDI Processor')\n",
        "print('Starting up...')\n",
        "###########\n",
        "\n",
        "files_count = 0\n",
        "\n",
        "gfiles = []\n",
        "\n",
        "melody_chords_f = []\n",
        "\n",
        "stats = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "print('Processing MIDI files. Please wait...')\n",
        "for f in tqdm(filez[:int(len(filez) * dataset_ratio)]):\n",
        "    try:\n",
        "        fn = os.path.basename(f)\n",
        "        fn1 = fn.split('.')[0]\n",
        "\n",
        "        #print('Loading MIDI file...')\n",
        "        score = TMIDIX.midi2ms_score(open(f, 'rb').read())\n",
        "\n",
        "        events_matrix = []\n",
        "\n",
        "        itrack = 1\n",
        "\n",
        "        patches = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "        patch_map = [[0, 1, 2, 3, 4, 5, 6, 7], # Piano \n",
        "                     [24, 25, 26, 27, 28, 29, 30], # Guitar\n",
        "                     [32, 33, 34, 35, 36, 37, 38, 39], # Bass\n",
        "                     [40, 41], # Violin\n",
        "                     [42, 43], # Cello\n",
        "                     [46], # Harp\n",
        "                     [56, 57, 58, 59, 60], # Trumpet\n",
        "                     [71, 72], # Clarinet\n",
        "                     [73, 74, 75], # Flute\n",
        "                     [-1], # Fake Drums\n",
        "                     [52, 53], # Choir\n",
        "                     [16, 17, 18, 19, 20] # Organ\n",
        "                    ]\n",
        "\n",
        "        while itrack < len(score):\n",
        "            for event in score[itrack]:         \n",
        "                if event[0] == 'note' or event[0] == 'patch_change':\n",
        "                    events_matrix.append(event)\n",
        "            itrack += 1\n",
        "\n",
        "        events_matrix.sort(key=lambda x: x[1])\n",
        "\n",
        "        events_matrix1 = []\n",
        "        for event in events_matrix:\n",
        "                if event[0] == 'patch_change':\n",
        "                    patches[event[2]] = event[3]\n",
        "\n",
        "                if event[0] == 'note':\n",
        "                    event.extend([patches[event[3]]])\n",
        "                    once = False\n",
        "                    \n",
        "                    for p in patch_map:\n",
        "                        if event[6] in p and event[3] != 9: # Except the drums\n",
        "                            event[3] = patch_map.index(p)\n",
        "                            once = True\n",
        "                            \n",
        "                    if not once and event[3] != 9: # Except the drums\n",
        "                        event[3] = 0 # All other instruments/patches channel\n",
        "                        event[5] = max(80, event[5])\n",
        "                        \n",
        "                    if event[3] < 12: # We won't write chans 11-16 for now...\n",
        "                        events_matrix1.append(event)\n",
        "                        stats[event[3]] += 1\n",
        "\n",
        "        # Sorting...\n",
        "        events_matrix1.sort(key=lambda x: (x[1], x[3]))\n",
        "\n",
        "        # recalculating timings\n",
        "        for e in events_matrix1:\n",
        "            e[1] = int(e[1] / 16)\n",
        "            e[2] = int(e[2] / 32)\n",
        "        \n",
        "        # final processing...\n",
        "\n",
        "        pe = events_matrix1[0]\n",
        "        for e in events_matrix1:\n",
        "\n",
        "            time = max(0, min(127, e[1]-pe[1]))\n",
        "            dur = max(1, min(127, e[2]))\n",
        "            cha = max(0, min(11, e[3]))\n",
        "            ptc = max(1, min(127, e[4]))\n",
        "            vel = max(19, min(127, e[5]))\n",
        "\n",
        "            div_vel = int(vel / 19)\n",
        "\n",
        "            chan_vel = (cha * 11) + div_vel\n",
        "\n",
        "            melody_chords_f.extend([chan_vel, time+128, dur+256, ptc+384])\n",
        "\n",
        "            pe = e\n",
        "\n",
        "        # Break between compositions\n",
        "        melody_chords_f.extend([0, 127+128, 127+256, 0+384])\n",
        "        melody_chords_f.extend([0, 127+128, 127+256, 0+384])\n",
        "\n",
        "        files_count += 1\n",
        "\n",
        "        if files_count % 4000 == 0:\n",
        "          count = str(files_count)\n",
        "          TMIDIX.Tegridy_Any_Pickle_File_Writer(melody_chords_f, '/content/INTS/Euterpe_INTs_'+count)\n",
        "          melody_chords_f = []\n",
        "        \n",
        "    except KeyboardInterrupt:\n",
        "        print('Saving current progress and quitting...')\n",
        "        break  \n",
        "\n",
        "    except:\n",
        "        print('Bad MIDI:', f)\n",
        "        continue\n",
        "\n",
        "count = str(files_count)\n",
        "TMIDIX.Tegridy_Any_Pickle_File_Writer(melody_chords_f, '/content/INTS/Euterpe_INTs_'+count)\n",
        "\n",
        "print('=' * 70)\n",
        "        \n",
        "print('Done!')   \n",
        "print('=' * 70)\n",
        "\n",
        "print('Resulting Stats:')\n",
        "print('=' * 70)\n",
        "print('Total MIDI Files:', files_count)\n",
        "print('=' * 70)\n",
        "\n",
        "print('Piano:', stats[0])\n",
        "print('Guitar:', stats[1])\n",
        "print('Bass:', stats[2])\n",
        "print('Violin:', stats[3])\n",
        "print('Cello:', stats[4])\n",
        "print('Harp:', stats[5])\n",
        "print('Trumpet:', stats[6])\n",
        "print('Clarinet:', stats[7])\n",
        "print('Flute:', stats[8])\n",
        "print('Drums:', stats[9])\n",
        "print('Choir:', stats[10])\n",
        "print('Organ:', stats[11])\n",
        "\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xkHKfUoucXJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (FROM THE TRAIN DATA PACK) Download pre-processed and ready-to-use Euterpe training data\n",
        "\n",
        "## Once you downloaded and unziped the train data pack, you can jump straight to INTs loading code below"
      ],
      "metadata": {
        "id": "QgaPjTHxrJQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Euterpe Training Data Pack (2GB compressed)\n",
        "%cd /content/INTS/\n",
        "!wget --no-check-certificate -O 'Euterpe-Training-Data.zip' \"https://onedrive.live.com/download?cid=8A0D502FC99C608F&resid=8A0D502FC99C608F%2118665&authkey=AF0mW39Iqv0gR5o\"\n",
        "!unzip 'Euterpe-Training-Data.zip'\n",
        "!rm 'Euterpe-Training-Data.zip'\n",
        "%cd /content/"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7CQI2kspra3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (LOAD INTs)"
      ],
      "metadata": {
        "id": "O9iACjm42uTz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "0826f622-2edc-4f09-9a01-58df049738d4",
          "kernelId": ""
        },
        "id": "t-jV34sBHX9z",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Load INTs...\n",
        "\n",
        "#@markdown PLEASE NOTE: You will need at least 32GB RAM to load all files\n",
        "\n",
        "print('Processing the dataset...')\n",
        "\n",
        "dataset_addr = \"/content/INTS\"\n",
        "# os.chdir(dataset_addr)\n",
        "filez = list()\n",
        "for (dirpath, dirnames, filenames) in os.walk(dataset_addr):\n",
        "    filez += [os.path.join(dirpath, file) for file in filenames]\n",
        "print('=' * 70)\n",
        "\n",
        "filez.sort()\n",
        "\n",
        "print('Processing MIDI files. Please wait...')\n",
        "\n",
        "train_data = torch.Tensor()\n",
        "\n",
        "for f in tqdm(filez):\n",
        "  fn = f.split('.')[0]\n",
        "  train_data = torch.cat((train_data, torch.Tensor(TMIDIX.Tegridy_Any_Pickle_File_Reader(fn))))\n",
        "  print('Loaded file:', f)\n",
        "\n",
        "print('Done!')        \n",
        "print('=' * 70)\n",
        "        \n",
        "print('Total INTs:', len(train_data))\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ye9rNzOHX90"
      },
      "source": [
        "# Test the resulting INTs dataset..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Test INTs\n",
        "print('Sample INTs', train_data[:15])\n",
        "\n",
        "out = train_data[:160000].tolist()\n",
        "\n",
        "if len(out) != 0:\n",
        "    \n",
        "    song = out\n",
        "    song_f = []\n",
        "    time = 0\n",
        "    dur = 0\n",
        "    vel = 0\n",
        "    pitch = 0\n",
        "    channel = 0\n",
        "\n",
        "    son = []\n",
        "\n",
        "    song1 = []\n",
        "\n",
        "    for s in song:\n",
        "      if s > 127:\n",
        "        son.append(s)\n",
        "\n",
        "      else:\n",
        "        if len(son) == 4:\n",
        "          song1.append(son)\n",
        "        son = []\n",
        "        son.append(s)\n",
        "    \n",
        "    for s in song1:\n",
        "\n",
        "        channel = s[0] // 11\n",
        "\n",
        "        vel = (s[0] % 11) * 19\n",
        "\n",
        "        time += (s[1]-128) * 16\n",
        "            \n",
        "        dur = (s[2] - 256) * 32\n",
        "        \n",
        "        pitch = (s[3] - 384)\n",
        "                                  \n",
        "        song_f.append(['note', time, dur, channel, pitch, vel ])\n",
        "\n",
        "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
        "                                                        output_signature = 'Euterpe',  \n",
        "                                                        output_file_name = '/content/Euterpe-Music-Composition', \n",
        "                                                        track_name='Project Los Angeles',\n",
        "                                                        list_of_MIDI_patches=[0, 24, 32, 40, 42, 46, 56, 71, 73, 0, 53, 19, 0, 0, 0, 0],\n",
        "                                                        number_of_ticks_per_quarter=500)\n",
        "\n",
        "    print('Done!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zppMJ8gA3L4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (PREP DATALOADER)"
      ],
      "metadata": {
        "id": "eMrq1osy3_ZG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "53252e52-5e68-4e60-8e4d-a584667749a4",
          "kernelId": ""
        },
        "id": "lT0TyqUnpxu_",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Prep the dataloader\n",
        "\n",
        "SEQ_LEN = max_seq\n",
        "\n",
        "BATCH_SIZE = 1 # Change this to your specs\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "print('=' * 50)\n",
        "print('Loading training data...')\n",
        "\n",
        "class MusicSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        rand = secrets.randbelow((self.data.size(0)-(self.seq_len)) // (self.seq_len)) * (self.seq_len)\n",
        "\n",
        "        x = self.data[rand: rand + self.seq_len].long()\n",
        "        trg = self.data[(rand+1): (rand+1) + self.seq_len].long()\n",
        "        \n",
        "        return x, trg\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.seq_len\n",
        "\n",
        "train_dataset = MusicSamplerDataset(train_data, SEQ_LEN)\n",
        "val_dataset   = MusicSamplerDataset(train_data, SEQ_LEN)\n",
        "train_loader  = DataLoader(train_dataset, batch_size = BATCH_SIZE)\n",
        "val_loader    = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
        "\n",
        "print('=' * 50)\n",
        "print('Sample train dataset:', train_dataset[0])\n",
        "print('Sample val dataset:', val_dataset[0])\n",
        "print('=' * 50)\n",
        "print('Train loader length:', len(train_loader))\n",
        "print('Val loader length:', len(val_loader))\n",
        "print('=' * 50)\n",
        "print('Done! Enjoy! :)')\n",
        "print('=' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkVqviDzJOrv"
      },
      "source": [
        "# (TRAIN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9CBW8xYupH8"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "4aa21407-a3e9-4ed2-9bf1-83c295482b8a",
          "kernelId": ""
        },
        "id": "2moo7uUmpxvC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Train\n",
        "\n",
        "DIC_SIZE = 512\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "config = GPTConfig(DIC_SIZE, \n",
        "                   max_seq,\n",
        "                   dim_feedforward=2048,\n",
        "                   n_layer=24, \n",
        "                   n_head=8, \n",
        "                   n_embd=1024,\n",
        "                   enable_rpr=True,\n",
        "                   er_len=max_seq)\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = GPT(config)\n",
        "\n",
        "model = nn.DataParallel(model)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "#=====\n",
        "\n",
        "init_step = 0\n",
        "lr = LR_DEFAULT_START\n",
        "lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
        "eval_loss_func = nn.CrossEntropyLoss(ignore_index=DIC_SIZE)\n",
        "train_loss_func = eval_loss_func\n",
        "\n",
        "# opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
        "\n",
        "opt = Adam(model.parameters()) # Default optimizer settings work better on large datasets\n",
        "\n",
        "lr_scheduler = LambdaLR(opt, lr_stepper.step)\n",
        "\n",
        "\n",
        "#===\n",
        "\n",
        "best_eval_acc        = 0.0\n",
        "best_eval_acc_epoch  = -1\n",
        "best_eval_loss       = float(\"inf\")\n",
        "best_eval_loss_epoch = -1\n",
        "best_acc_file = '/content/gpt2_rpr_acc.pth'\n",
        "best_loss_file = '/content/gpt2_rpr_loss.pth'\n",
        "loss_train, loss_val, acc_val = [], [], []\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    new_best = False\n",
        "    \n",
        "    loss = train(epoch+1, \n",
        "                 model, train_loader, \n",
        "                 train_loss_func, \n",
        "                 opt, \n",
        "                 lr_scheduler, \n",
        "                 num_iters=-1, \n",
        "                 save_checkpoint_steps=4000)\n",
        "    \n",
        "    loss_train.append(loss)\n",
        "    \n",
        "    eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)\n",
        "    loss_val.append(eval_loss)\n",
        "    acc_val.append(eval_acc)\n",
        "    \n",
        "    if(eval_acc > best_eval_acc):\n",
        "        best_eval_acc = eval_acc\n",
        "        best_eval_acc_epoch  = epoch+1\n",
        "        torch.save(model.state_dict(), best_acc_file)\n",
        "        new_best = True\n",
        "\n",
        "    if(eval_loss < best_eval_loss):\n",
        "        best_eval_loss       = eval_loss\n",
        "        best_eval_loss_epoch = epoch+1\n",
        "        torch.save(model.state_dict(), best_loss_file)\n",
        "        new_best = True\n",
        "    \n",
        "    if(new_best):\n",
        "        print(\"Best eval acc epoch:\", best_eval_acc_epoch)\n",
        "        print(\"Best eval acc:\", best_eval_acc)\n",
        "        print(\"\")\n",
        "        print(\"Best eval loss epoch:\", best_eval_loss_epoch)\n",
        "        print(\"Best eval loss:\", best_eval_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "72338f3f-34c4-40e3-a48a-42ed9729466a",
          "kernelId": ""
        },
        "id": "R4LIXk1vHX92",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Eval funct to eval separately if needed\n",
        "\n",
        "DIC_SIZE = 512\n",
        "\n",
        "#=====\n",
        "\n",
        "init_step = 0\n",
        "lr = LR_DEFAULT_START\n",
        "lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
        "eval_loss_func = nn.CrossEntropyLoss(ignore_index=DIC_SIZE)\n",
        "train_loss_func = eval_loss_func\n",
        "\n",
        "opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
        "lr_scheduler = LambdaLR(opt, lr_stepper.step)\n",
        "\n",
        "\n",
        "eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdKFoeke9L7H"
      },
      "source": [
        "# (SAVE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "id": "73bea62d-084b-4f9a-9e55-2b34a932a7a4",
          "kernelId": ""
        },
        "id": "gqyDatHC9X1z"
      },
      "outputs": [],
      "source": [
        "#@title Save the model\n",
        "\n",
        "print('Saving the model...')\n",
        "full_path_to_model_checkpoint = \"/content/Euterpe-Trained-Model.pth\" #@param {type:\"string\"}\n",
        "torch.save(model.state_dict(), full_path_to_model_checkpoint)\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzCMd94Tu_gz"
      },
      "source": [
        "# Congrats! You did it! :)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}